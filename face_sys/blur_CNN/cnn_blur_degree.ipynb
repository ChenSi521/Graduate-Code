{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import nn,optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "\n",
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom(env = u'blur_degrees')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gaussion_kernel(nn.Module):\n",
    "    def __init__(self,inchannel=1,outchannel=1,stride=1):\n",
    "        super().__init__()\n",
    "        self.gaus_conv1 = nn.Conv2d(inchannel,outchannel,(3,3),stride,padding=0,dilation=1,bias=False)    #这个padding可以保证前后图片大小相等。\n",
    "        self.gaus_conv1.weight.data = (t.Tensor([[1/16,1/8,1/16],[1/8,1/4,1/8],[1/16,1/8,1/16]])).view(1,1,3,3)     #高斯模板\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(x[:,0,:,:].shape)   #dim=3            #这个维数不够，所以下面要加上unsqueeze(1)\n",
    "        x1 = self.gaus_conv1(x[:,0,:,:].unsqueeze(1))    #参考P144\n",
    "        x2 = self.gaus_conv1(x[:,1,:,:].unsqueeze(1))\n",
    "        x3 = self.gaus_conv1(x[:,2,:,:].unsqueeze(1))\n",
    "        x = t.cat((x1,x2,x3),1)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gaussion_kernel0(nn.Module):\n",
    "    def __init__(self,inchannel=1,outchannel=1,stride=1):\n",
    "        super().__init__()\n",
    "        self.gaus_conv1 = nn.Conv2d(inchannel,outchannel,(3,3),stride,padding=0,dilation=1,bias=False)    #这个padding可以保证前后图片大小相等。\n",
    "        self.gaus_conv1.weight.data = (t.Tensor([[1/16,1/8,1/16],[1/8,1/4,1/8],[1/16,1/8,1/16]])).view(1,1,3,3)     #高斯模板\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(x[:,0,:,:].shape)   #dim=3            #这个维数不够，所以下面要加上unsqueeze(1)\n",
    "        x1 = self.gaus_conv1(x[:,0,:,:].unsqueeze(1))    #参考P144\n",
    "        x2 = self.gaus_conv1(x[:,1,:,:].unsqueeze(1))\n",
    "        x3 = self.gaus_conv1(x[:,2,:,:].unsqueeze(1))\n",
    "        x4 = self.gaus_conv1(x[:,3,:,:].unsqueeze(1))    \n",
    "        x5 = self.gaus_conv1(x[:,4,:,:].unsqueeze(1))\n",
    "        x6 = self.gaus_conv1(x[:,5,:,:].unsqueeze(1))\n",
    "        x = t.cat((x1,x2,x3,x4,x5,x6),1)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gaussion_kernel1(nn.Module):\n",
    "    def __init__(self,inchannel=1,outchannel=1,stride=1):\n",
    "        super().__init__()\n",
    "        self.gaus_conv1 = nn.Conv2d(inchannel,outchannel,(3,3),stride,padding=0,dilation=1,bias=False)    #这个padding可以保证前后图片大小相等。\n",
    "        self.gaus_conv1.weight.data = (t.Tensor([[1/16,1/8,1/16],[1/8,1/4,1/8],[1/16,1/8,1/16]])).view(1,1,3,3)     #高斯模板\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(x[:,0,:,:].shape)   #dim=3            #这个维数不够，所以下面要加上unsqueeze(1)\n",
    "        x1 = self.gaus_conv1(x[:,0,:,:].unsqueeze(1))    #参考P144\n",
    "        x2 = self.gaus_conv1(x[:,1,:,:].unsqueeze(1))\n",
    "        x3 = self.gaus_conv1(x[:,2,:,:].unsqueeze(1))\n",
    "        x4 = self.gaus_conv1(x[:,3,:,:].unsqueeze(1))    \n",
    "        x5 = self.gaus_conv1(x[:,4,:,:].unsqueeze(1))\n",
    "        x6 = self.gaus_conv1(x[:,5,:,:].unsqueeze(1))\n",
    "        x7 = self.gaus_conv1(x[:,6,:,:].unsqueeze(1))\n",
    "        x8 = self.gaus_conv1(x[:,7,:,:].unsqueeze(1))\n",
    "        \n",
    "        x9 = self.gaus_conv1(x[:,0,:,:].unsqueeze(1))    #参考P144\n",
    "        x10 = self.gaus_conv1(x[:,1,:,:].unsqueeze(1))\n",
    "        x11 = self.gaus_conv1(x[:,2,:,:].unsqueeze(1))\n",
    "        x12 = self.gaus_conv1(x[:,3,:,:].unsqueeze(1))    \n",
    "        #x13 = self.gaus_conv1(x[:,4,:,:].unsqueeze(1))\n",
    "        #x14 = self.gaus_conv1(x[:,5,:,:].unsqueeze(1))\n",
    "        #x15 = self.gaus_conv1(x[:,6,:,:].unsqueeze(1))\n",
    "        #x16 = self.gaus_conv1(x[:,7,:,:].unsqueeze(1))\n",
    "        x = t.cat((x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12),1)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       "   0.0625  0.1250  0.0625\n",
       "   0.1250  0.2500  0.1250\n",
       "   0.0625  0.1250  0.0625\n",
       " [torch.FloatTensor of size 1x1x3x3]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#这个cell没用，不用执行\n",
    "gaus_layer = gaussion_kernel()\n",
    "gaus_layer1 = gaussion_kernel1()\n",
    "list(gaus_layer.parameters())     #说明我的方法还是可以的，存在可学习的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#有3高斯处理，3，12,24\n",
    "layers1 = 12\n",
    "layers2 = 24\n",
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(   #这一层只是进行尺寸变化。\n",
    "                                    #gaussion_kernel(),\n",
    "                                    nn.Conv2d(3,3,(5,5),stride=2,padding=0)     #这样可以保证输入120*120的图片时，输出为60*60\n",
    "                                    )\n",
    "        self.layer1 = nn.Sequential(\n",
    "                                    #gaussion_kernel(),\n",
    "                                    nn.Conv2d(3,layers1,(7,7),stride=1,padding=0),    #为了减少0填充对于结果的影响，不进行边缘填充，反正层数少。\n",
    "                                    nn.BatchNorm2d(layers1),\n",
    "                                    nn.ReLU(True),\n",
    "                                    nn.AvgPool2d(2,2)\n",
    "                                    #nn.AdaptiveAvgPool2d(27)\n",
    "                                    )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "                                    #gaus_layer(),\n",
    "                                    #gaussion_kernel1(),\n",
    "                                    nn.Conv2d(layers1,layers2,(5,5),stride=1,padding=0),\n",
    "                                    nn.BatchNorm2d(layers2),\n",
    "                                    nn.ReLU(True),\n",
    "                                    nn.AvgPool2d(3,3)\n",
    "                                    )\n",
    "        \n",
    "        \n",
    "        #self.gaus_layer2 = gaus_layer()\n",
    "        #self.conv3 = nn.Conv2d(12,24,(3,3),stride=1,padding=1)\n",
    "        #self.pool2 = nn.AvgPool2d(2,2)\n",
    "        self.full_layer1 = nn.Sequential(                   #因为输入是16*6*6\n",
    "                                    nn.Linear(1176,64),     \n",
    "                                    nn.BatchNorm1d(64),\n",
    "                                    nn.ReLU(True)\n",
    "                                    )\n",
    "        self.full_layer2 = nn.Sequential(                  \n",
    "                                    nn.Linear(64,32),     \n",
    "                                    nn.BatchNorm1d(32),\n",
    "                                    nn.ReLU(True)\n",
    "                                    )\n",
    "        self.full_layer3 = nn.Sequential(                  \n",
    "                                    nn.Linear(32,16),     \n",
    "                                    nn.BatchNorm1d(16),\n",
    "                                    nn.ReLU(True)\n",
    "                                    )\n",
    "        self.full_layer_output = nn.Sequential(                   \n",
    "                                    nn.Linear(16,2),     \n",
    "                                    \n",
    "                                    )\n",
    "        #self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        #print(\"x.shape\",x.shape)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        #print(type(x))\n",
    "        #print(\"x.shape1\",x.shape)\n",
    "        x = self.full_layer1(x)\n",
    "        x = self.full_layer2(x)\n",
    "        x = self.full_layer3(x)\n",
    "        x = self.full_layer_output(x)\n",
    "        #x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#有3高斯处理，3，12,24\n",
    "class CNN_Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(   #这一层只是进行尺寸变化。\n",
    "                                    #gaus_layer(),\n",
    "                                    gaussion_kernel(),\n",
    "                                    nn.Conv2d(3,3,(5,5),stride=2,padding=0)     #这样可以保证输入120*120的图片时，输出为60*60\n",
    "                                    )\n",
    "        self.layer1 = nn.Sequential(\n",
    "                                    #gaus_layer(),\n",
    "                                    gaussion_kernel(),\n",
    "                                    nn.Conv2d(3,8,(7,7),stride=1,padding=0),    #为了减少0填充对于结果的影响，不进行边缘填充，反正层数少。\n",
    "                                    nn.BatchNorm2d(8),\n",
    "                                    nn.ReLU(True),\n",
    "                                    nn.AvgPool2d(2,2)\n",
    "                                    )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "                                    #gaus_layer(),\n",
    "                                    gaussion_kernel1(),\n",
    "                                    nn.Conv2d(6,12,(5,5),stride=1,padding=0),\n",
    "                                    nn.BatchNorm2d(12),\n",
    "                                    nn.ReLU(True),\n",
    "                                    nn.AvgPool2d(3,3)\n",
    "                                    )\n",
    "        \n",
    "        \n",
    "        #self.gaus_layer2 = gaus_layer()\n",
    "        #self.conv3 = nn.Conv2d(12,24,(3,3),stride=1,padding=1)\n",
    "        #self.pool2 = nn.AvgPool2d(2,2)\n",
    "        self.full_layer1 = nn.Sequential(                   #因为输入是12*6*6    去掉高斯层为12*7*7\n",
    "                                    nn.Linear(432,64),     \n",
    "                                    nn.BatchNorm1d(64),\n",
    "                                    nn.ReLU(True)\n",
    "                                    )\n",
    "        self.full_layer2 = nn.Sequential(                  \n",
    "                                    nn.Linear(64,32),     \n",
    "                                    nn.BatchNorm1d(32),\n",
    "                                    nn.ReLU(True)\n",
    "                                    )\n",
    "        self.full_layer_output = nn.Sequential(                   \n",
    "                                    nn.Linear(32,2),     \n",
    "                                    \n",
    "                                    )\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        #print(\"x.shape\",x.shape)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        #print(type(x))\n",
    "        #print(\"x.shape1\",x.shape)\n",
    "        x = self.full_layer1(x)\n",
    "        x = self.full_layer2(x)\n",
    "        x = self.full_layer_output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])   #感觉不应该进行方差标准化，因为最终图像就是使用方差来完成模糊程度判断的。\n",
    "#normalize = transforms.Normalize(mean=[0.5,0.5,0.5],std)\n",
    "transform0 = transforms.Compose([\n",
    "                                transforms.RandomRotation(20),         #图像旋转的角度\n",
    "                                transforms.RandomHorizontalFlip(),    #水平方向翻转\n",
    "                                transforms.ToTensor(),\n",
    "                                normalize,\n",
    "                                ])\n",
    "dataset = ImageFolder(\"D:\\\\newfolder43_1\",transform=transform0)\n",
    "#dataset.imgs   \n",
    "\n",
    "#print(dataset.shape)\n",
    "#print(dataset.mean(axis=(0,1,2))/255)\n",
    "#print(dataset.std(axis=(0,1,2))/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "num_epoches = 500\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "#dataiter = iter(dataloader)\n",
    "#imgs,labels = next(dataiter)\n",
    "#imgs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss(\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if t.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.cuda() \n",
    "#optimizer = optim.Adam(model.parameters(),lr=learning_rate,weight_decay=weight_decay)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([\n",
    "                        {'params':model.layer0[0].parameters(),'lr':0.0},\n",
    "                        {'params':model.layer0[1].parameters(),'lr':learning_rate},\n",
    "                       \n",
    "                        {'params':model.layer1[0].parameters(),'lr':0},\n",
    "                        {'params':model.layer1[1].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.layer1[2].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.layer1[3].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.layer1[4].parameters(),'lr':learning_rate},\n",
    "    \n",
    "                        {'params':model.layer2[0].parameters(),'lr':0},\n",
    "                        {'params':model.layer2[1].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.layer2[2].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.layer2[3].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.layer2[4].parameters(),'lr':learning_rate},\n",
    "    \n",
    "                        {'params':model.full_layer1[0].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.full_layer1[1].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.full_layer1[2].parameters(),'lr':learning_rate},\n",
    "    \n",
    "                        {'params':model.full_layer2[0].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.full_layer2[1].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.full_layer2[2].parameters(),'lr':learning_rate},\n",
    "    \n",
    "                        {'params':model.full_layer_output[0].parameters(),'lr':learning_rate},\n",
    "    \n",
    "                        #{'params':model.softmax[0].parameters(),'lr':learning_rate}\n",
    "                       ],weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去掉高斯层时的优化函数\n",
    "optimizer = optim.Adam([\n",
    "                        #{'params':model.layer0[0].parameters(),'lr':0.0},\n",
    "                        {'params':model.layer0[0].parameters(),'lr':learning_rate},\n",
    "                       \n",
    "                        #{'params':model.layer1[0].parameters(),'lr':0},\n",
    "                        {'params':model.layer1[0].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.layer1[1].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.layer1[2].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.layer1[3].parameters(),'lr':learning_rate},\n",
    "                        #{'params':model.layer1[4].parameters(),'lr':learning_rate},\n",
    "    \n",
    "                        #{'params':model.layer2[0].parameters(),'lr':0},\n",
    "                        {'params':model.layer2[0].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.layer2[1].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.layer2[2].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.layer2[3].parameters(),'lr':learning_rate},\n",
    "    \n",
    "                        {'params':model.full_layer1[0].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.full_layer1[1].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.full_layer1[2].parameters(),'lr':learning_rate},\n",
    "    \n",
    "                        {'params':model.full_layer2[0].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.full_layer2[1].parameters(),'lr':learning_rate},\n",
    "                        {'params':model.full_layer2[2].parameters(),'lr':learning_rate},\n",
    "    \n",
    "                        {'params':model.full_layer_output[0].parameters(),'lr':learning_rate},\n",
    "    \n",
    "                        #{'params':model.softmax[0].parameters(),'lr':learning_rate}\n",
    "                       ],weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start time  <===>   time.struct_time(tm_year=2018, tm_mon=6, tm_mday=4, tm_hour=16, tm_min=48, tm_sec=58, tm_wday=0, tm_yday=155, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "print(\"training start time  <===>  \",time.localtime())       #\n",
    "sum_loss = t.Tensor([0])     #多一个0元素，不会影响平均值\n",
    "for epoch in range(0,num_epoches):\n",
    "    for i,data in enumerate(dataloader,0):   #表示i 从0开始\n",
    "        data_batch, label = data\n",
    "        data_batch, label = Variable(data_batch.float()).cuda(),Variable(label).cuda()\n",
    "        output = model(data_batch)\n",
    "        #print(\"output.shape\",output.shape)\n",
    "        #print(output.cpu())\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output,label)\n",
    "        loss.backward()            #我终于知道，我的图为什么不下降了，我忘记反向传播了。。。。。。。。。。。。\n",
    "        optimizer.step()\n",
    "        #sum_loss.append(loss)\n",
    "        sum_loss = t.cat((sum_loss,loss.cpu().data),0)\n",
    "        x = i+epoch*len(dataloader)      #此时的x还只是个常数，不是列表，也不是np.array()\n",
    "        \n",
    "        if x%50 == 49:\n",
    "            loss_aver = sum_loss.mean()\n",
    "            sum_loss = t.Tensor([0])\n",
    "            #print(x)\n",
    "            #vis.line(X=x, Y=loss.cpu().data, win='face_angle',opts={'title': 'loss-batch', 'xlabel':'x','ylabel':'y'},update='append' if i>=0 else None)\n",
    "            vis.line(X=t.Tensor([x]), Y=t.Tensor([loss_aver]), win='blur_degrees33',opts={'title': 'loss-batch1', 'xlabel':'batch_num','ylabel':'loss_aver'},update='append' if x>49 else None)\n",
    "           # vis.updateTrace(X=t.Tensor([x]),Y=t.Tensor([loss_aver]),win='blur_degrees', name='1e-4_6.12.24_NoGaussion')\n",
    "print(\"training end time  <===>  \",time.localtime())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2018, tm_mon=4, tm_mday=30, tm_hour=12, tm_min=50, tm_sec=22, tm_wday=0, tm_yday=120, tm_isdst=0)\n",
      "training end time  <===>   time.struct_time(tm_year=2018, tm_mon=4, tm_mday=30, tm_hour=12, tm_min=50, tm_sec=25, tm_wday=0, tm_yday=120, tm_isdst=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "time.struct_time(tm_year=2018, tm_mon=4, tm_mday=30, tm_hour=12, tm_min=50, tm_sec=28, tm_wday=0, tm_yday=120, tm_isdst=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实验time.localtime()的使用方法\n",
    "print(time.localtime())\n",
    "time.sleep(3)\n",
    "print(\"training end time  <===>  \",time.localtime()) \n",
    "time.sleep(3)\n",
    "time.localtime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存和加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(model.state_dict(),\"C:\\\\Users\\\\SiChen\\\\face_sys\\\\blur_CNN\\\\model_save\\\\cnn_blur_network_500_1e-4_3.12.24_4full-layers_NoGaussion_Nosoftmax_newdataset.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型必须在，前面定义模型之后，即在前面的model = ....之后才能执行这一行。\n",
    "model.load_state_dict(t.load(\"C:\\\\Users\\\\SiChen\\\\face_sys\\\\FC_network\\\\model_save\\\\cnn_blur_network_500_1e-4_softmax.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下是测试部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize = transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "transform = transforms.Compose([\n",
    "                                #transforms.RandomRotation(20),         #图像旋转的角度\n",
    "                                #transforms.RandomHorizontalFlip(),    #水平方向翻转\n",
    "                                transforms.ToTensor(),\n",
    "                                normalize,\n",
    "                                ])\n",
    "test_dataset = ImageFolder(\"D:\\\\newfolder43_2\",transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3184\n",
      "[torch.IntTensor of size 1]\n",
      "\n",
      "3354\n",
      "0.9493142516398331\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "model.eval()\n",
    "test_right_num = 0\n",
    "test_right_num = t.Tensor([test_right_num]).int()\n",
    "test_right_num = Variable(test_right_num)\n",
    "for data in test_dataloader:\n",
    "    data_batch,label = data\n",
    "    data_batch,label = Variable(data_batch.float(),volatile=True).cuda(),Variable(label,volatile=True).cuda()\n",
    "    out = model(data_batch)\n",
    "    _,pred = t.max(out.cpu(),1)\n",
    "    num_correct = (pred==label.cpu()).sum()\n",
    "    #print(num_correct)\n",
    "    num_correct = num_correct.int()     #是torch.ByteTensor转为torch.IntTensor类型。size为1\n",
    "    test_right_num = test_right_num + num_correct\n",
    "    #print(\"test_right_num\",test_right_num)\n",
    "    \n",
    "acc = (float(test_right_num))/len(test_dataset)\n",
    "print(test_right_num)\n",
    "print(len(test_dataset))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\newfolder23_51\\clear_face\\picture_10242_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_10243_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_10244_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_1032_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_10332_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_10333_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_1039_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_1040_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_1070_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_10874_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_10924_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_10930_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_10933_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_10966_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11079_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11085_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11087_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11089_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11093_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11095_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11097_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11102_.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\newfolder23_51\\clear_face\\picture_11122_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11310_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_1131_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11427_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11508_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11515_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_11611_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12074_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12076_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12080_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12083_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12085_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12088_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12092_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12095_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12099_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12101_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12104_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12107_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12133_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12135_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12137_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12140_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12143_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12159_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12231_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12253_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12255_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12366_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12416_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12424_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12544_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12612_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12616_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12825_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12826_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12828_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12830_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12831_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_12994_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_1354_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_1373_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_14040_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_14070_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_14655_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_14657_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_14659_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_14661_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_14662_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_14770_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_193_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_196_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_197_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2051_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2260_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2576_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2588_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2602_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2603_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2655_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2656_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2779_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2785_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2788_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2791_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2797_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2800_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2905_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_2925_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_3103_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_3426_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_3471_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_3474_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_3475_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_3476_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_3504_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_3506_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_3510_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_3516_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_3538_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_3727_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_4012_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_4024_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_41_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_4472_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_4741_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_4829_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_4848_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_4936_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_4937_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_5116_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_5195_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_5524_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_5530_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_5532_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_5540_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_6822_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_6951_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_7089_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_7266_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_7271_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_7272_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_7273_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_7689_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_7826_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_7847_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_7919_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_7920_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_7922_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_7938_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_8579_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_8580_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_8738_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_8741_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_8748_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_8750_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_8943_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_8972_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_8974_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_8991_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_9022_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_9023_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_9025_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_9026_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_9066_.png\n",
      "D:\\newfolder23_51\\clear_face\\picture_937_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_0_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_10001_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_10003_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15158_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15159_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15160_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15162_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15166_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15170_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15175_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15176_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15177_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15178_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15191_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15193_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15194_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15195_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15196_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15218_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15221_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15224_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15229_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15230_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15233_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15237_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15241_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15242_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15249_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15251_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15253_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15254_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15256_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15259_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15267_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15269_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15270_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15271_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15272_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15273_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15274_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15275_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15277_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15279_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15280_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15282_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15283_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15284_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15285_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15287_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15292_.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\newfolder23_51\\fuzzy_face\\picture_15297_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15299_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15303_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15312_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15337_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15338_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_15353_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_3656_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_7235_.png\n",
      "D:\\newfolder23_51\\fuzzy_face\\picture_7237_.png\n",
      "Variable containing:\n",
      " 189\n",
      "[torch.IntTensor of size 1]\n",
      "\n",
      "208\n",
      "0.9086538461538461\n"
     ]
    }
   ],
   "source": [
    "#能输出错误的图片的测试代码\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "clear_wrong_picture = \"D:\\\\newfolder25\\\\clear_face\"          #保存错误的人脸的文件夹\n",
    "fuzzy_wrong_picture = \"D:\\\\newfolder25\\\\fuzzy_face\"\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "test_right_num = 0\n",
    "test_right_num = t.Tensor([test_right_num]).int()\n",
    "test_right_num = Variable(test_right_num)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "transform = transforms.Compose([\n",
    "                                #transforms.RandomRotation(20),         #图像旋转的角度\n",
    "                                #transforms.RandomHorizontalFlip(),    #水平方向翻转\n",
    "                                transforms.ToTensor(),\n",
    "                                normalize,\n",
    "                                ])\n",
    "test_dataset = ImageFolder(\"D:\\\\newfolder43_2\")\n",
    "\n",
    "for img0, label0 in test_dataset.imgs:            #!!!!!!!!!!!!!!!!!!!!!只有这样我才能得到需要的名字。\n",
    "    print(img0)\n",
    "    #print(label0)\n",
    "    img = Image.open(img0)                  #书本P108\n",
    "    img = transform(img)         \n",
    "    img = img.unsqueeze(0)                  #书本P109\n",
    "    label = Variable(t.Tensor([label0]))\n",
    "    label = label.long()\n",
    "    \n",
    "    img, label = Variable(img.float()).cuda(),label.cuda()\n",
    "    out = model(img)\n",
    "    #print(out.data)\n",
    "    _,pred = t.max(out.cpu(),1)                 #\n",
    "    num_correct = (pred==label.cpu()).sum()\n",
    "    #print(num_correct)\n",
    "    num_correct = num_correct.int()     #是torch.ByteTensor转为torch.IntTensor类型。size为1\n",
    "    test_right_num = test_right_num + num_correct\n",
    "    \n",
    "    if (pred==label.cpu()).data[0] == 0:   #判断model处理后的结果是否正确。\n",
    "        if not label0:            #因为clear_face对应的id是0.见前面的test_dataset.class_to_idx\n",
    "            shutil.copy(img0,clear_wrong_picture)\n",
    "            #print(\"F\")\n",
    "        else:\n",
    "            #print(\"F\")\n",
    "            shutil.copy(img0,fuzzy_wrong_picture)\n",
    "    \n",
    "\n",
    "acc = (float(test_right_num))/len(test_dataset)\n",
    "print(test_right_num)\n",
    "print(len(test_dataset))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n"
     ]
    }
   ],
   "source": [
    "#无用的cell\n",
    "import models\n",
    "#dir(models.__builtins__)\n",
    "print(dir(models))\n",
    "#dir(models.__path__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
