{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch as t\n",
    "import visdom\n",
    "import time\n",
    "\n",
    "from torch import nn,optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils import data\n",
    "\n",
    "vis = visdom.Visdom(env = 'grad_FC')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_ = np.array([[1/16,1/8,1/16],[1/8,1/4,1/8],[1/16,1/8,1/16]])\n",
    "\n",
    "p = np.zeros((28,3,3))\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,0] = 1;zeros[0,1] = 1; p[0] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,0] = 1;zeros[0,2] = 1; p[1] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,0] = 1;zeros[1,0] = 1; p[2] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,0] = 1;zeros[1,2] = 1; p[3] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,0] = 1;zeros[2,0] = 1; p[4] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,0] = 1;zeros[2,1] = 1; p[5] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,0] = 1;zeros[2,2] = 1; p[6] = zeros\n",
    "\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,1] = 1;zeros[0,2] = 1; p[7] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,1] = 1;zeros[1,0] = 1; p[8] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,1] = 1;zeros[1,2] = 1; p[9] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,1] = 1;zeros[2,0] = 1; p[10] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,1] = 1;zeros[2,1] = 1; p[11] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,1] = 1;zeros[2,2] = 1; p[12] = zeros\n",
    "\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,2] = 1;zeros[1,0] = 1; p[13] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,2] = 1;zeros[1,2] = 1; p[14] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,2] = 1;zeros[2,0] = 1; p[15] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,2] = 1;zeros[2,1] = 1; p[16] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[0,2] = 1;zeros[2,2] = 1; p[17] = zeros\n",
    "\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[1,0] = 1;zeros[1,2] = 1; p[18] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[1,0] = 1;zeros[2,0] = 1; p[19] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[1,0] = 1;zeros[2,1] = 1; p[20] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[1,0] = 1;zeros[2,2] = 1; p[21] = zeros\n",
    "\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[1,2] = 1;zeros[2,0] = 1; p[22] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[1,2] = 1;zeros[2,1] = 1; p[23] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[1,2] = 1;zeros[2,2] = 1; p[24] = zeros\n",
    "\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[2,0] = 1;zeros[2,1] = 1; p[25] = zeros\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[2,0] = 1;zeros[2,2] = 1; p[26] = zeros\n",
    "\n",
    "zeros = np.zeros((3,3));zeros[1,1] = -2;zeros[2,1] = 1;zeros[2,2] = 1; p[27] = zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络model\n",
    "class FC_Net(nn.Module):\n",
    "    def __init__(self,input_dim,n_hidden_1,n_hidden_2,n_hidden_3,output_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                                    \n",
    "                                    nn.Linear(input_dim,n_hidden_1),\n",
    "                                    nn.BatchNorm1d(n_hidden_1),\n",
    "                                    nn.ReLU(True)\n",
    "                                    )\n",
    "        self.layer2 = nn.Sequential(\n",
    "                                    nn.Linear(n_hidden_1,n_hidden_2),\n",
    "                                    nn.BatchNorm1d(n_hidden_2),\n",
    "                                    nn.ReLU(True)\n",
    "                                    )\n",
    "        self.layer3 = nn.Sequential(\n",
    "                                    nn.Linear(n_hidden_2,n_hidden_3),\n",
    "                                    nn.BatchNorm1d(n_hidden_3),\n",
    "                                    nn.ReLU(True)\n",
    "                                    )\n",
    "        self.layer_out = nn.Sequential(\n",
    "                                    nn.Linear(n_hidden_3,output_dim),\n",
    "                                    #nn.BatchNorm1d(output_dim),\n",
    "                                    #nn.ReLU(True)\n",
    "                                       )\n",
    "\n",
    "    def forward(self,x):\n",
    "        #print(\"x.shape\",x.shape)\n",
    "        x = self.layer1(x)\n",
    "        #print(\"x.shape1\",x.shape)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer_out(x)\n",
    "        #x = self.softmax(x)\n",
    "        #print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class var_dataset(data.Dataset):\n",
    "    def __init__(self,root,transforms0=transforms.ToTensor()):\n",
    "        self.dataset0 = ImageFolder(root)\n",
    "        self.labels = [img[1] for img in self.dataset0.imgs]\n",
    "        self.transforms0 = transforms0\n",
    "        \n",
    "    def __getitem__(self,index):        \n",
    "        label = self.dataset0[index][1]\n",
    "        #image = np.asarray(self.dataset0[index][0])         #这一行说明，cv2也是使用的numpy的数据（矩阵）\n",
    "        image_gaussion = cv2.filter2D(np.asarray(self.dataset0[index][0]),cv2.CV_16S,kernel_)\n",
    "        img_2grad = np.zeros((28,120,120,3))\n",
    "        var_array = np.zeros((1,84))\n",
    "        var_array1 = np.zeros((1,28))\n",
    "        aver_array = np.zeros((1,84))\n",
    "        aver_array1 = np.zeros((1,28))\n",
    "        for i in range(28):\n",
    "            img_2grad[i] = cv2.filter2D(image_gaussion,cv2.CV_16S,p[i])\n",
    "            var_array[0,3*i] = img_2grad[i][:,:,0].var()\n",
    "            var_array[0,3*i+1] = img_2grad[i][:,:,1].var()\n",
    "            var_array[0,3*i+2] = img_2grad[i][:,:,2].var()\n",
    "            aver_array[0,3*i] = img_2grad[i][:,:,0].mean()\n",
    "            aver_array[0,3*i+1] = img_2grad[i][:,:,1].mean()\n",
    "            aver_array[0,3*i+2] = img_2grad[i][:,:,2].mean()\n",
    "            var_array1[0,i] = img_2grad[i].var()\n",
    "            aver_array1[0,i] = img_2grad[i].mean()\n",
    "        \n",
    "        var_array_max = var_array.max()\n",
    "        var_array_min = var_array.min()\n",
    "        aver_array_max = aver_array.max()\n",
    "        aver_array_min = aver_array.min()\n",
    "        var_array_max1 = var_array1.max()\n",
    "        var_array_min1 = var_array1.min()\n",
    "        aver_array_max1 = aver_array1.max()\n",
    "        aver_array_min1 = aver_array1.min()\n",
    "        \n",
    "        var_array = np.true_divide((var_array-var_array_min),(var_array_max-var_array_min))\n",
    "        aver_array = np.true_divide((aver_array-aver_array_min),(aver_array_max-aver_array_min))\n",
    "        var_array1 = np.true_divide((var_array1-var_array_min1),(var_array_max1-var_array_min1))\n",
    "        aver_array1 = np.true_divide((aver_array1-aver_array_min1),(aver_array_max1-aver_array_min1))\n",
    "        \n",
    "        var_array = np.true_divide((var_array-0.5),0.5) \n",
    "        aver_array = np.true_divide((aver_array-0.5),0.5)\n",
    "        var_array1 = np.true_divide((var_array1-0.5),0.5) \n",
    "        aver_array1 = np.true_divide((aver_array1-0.5),0.5)\n",
    "        result_array = np.hstack((var_array,aver_array,var_array1,aver_array1)).reshape(224)\n",
    "        result_array = t.Tensor(result_array)\n",
    "        \n",
    "        return result_array,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1, -1,  2,  1]],\n",
       "\n",
       "       [[ 1, -1,  1,  1]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实验的CELL   \n",
    "#说明，hstack()可以多个矩阵。\n",
    "a = np.array([[1,-1,1,1]])\n",
    "b = np.array([[-1,-1,1,-1]])\n",
    "c = np.array([[-1,-1,0,-1]])\n",
    "d = np.array([[0,-1,1,-1]])\n",
    "np.true_divide((a-a.mean()),a.std())\n",
    "np.hstack((a,b,c,d))\n",
    "\n",
    "f = np.array([[[1,-1,2,1]],[[1,-1,1,1]]])\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实验的CELL\n",
    "dataset1 = ImageFolder(\"D:\\\\newfolder43_1\")\n",
    "img = dataset1[0][0]\n",
    "image = cv2.cvtColor(np.asarray(img),cv2.COLOR_RGB2BGR)\n",
    "cv2.imshow(\"OpenCV\",image)  \n",
    "cv2.waitKey() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728.6520611234355\n",
      "1728.6520611234355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实验的CELL\n",
    "image = cv2.imread(\"D:\\\\newfolder43_1\\\\clear_face\\\\picture_3144_.png\")\n",
    "#image = image[:,:,0]\n",
    "print(image.var())\n",
    "image = cv2.cvtColor(np.asarray(image),cv2.COLOR_RGB2BGR)\n",
    "print(image.var())\n",
    "cv2.imshow(\"OpenCV\",image)  \n",
    "cv2.waitKey() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 1 required positional argument: 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-e23c4c107e4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 \u001b[1;31m#transforms.RandomHorizontalFlip(),    #水平方向翻转\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                 \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                                 \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                                 ])\n\u001b[0;32m      9\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\\\newfolder43_1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'tensor'"
     ]
    }
   ],
   "source": [
    "#实验的CELL\n",
    "normalize = transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])   #感觉不应该进行方差标准化，因为最终图像就是使用方差来完成模糊程度判断的。\n",
    "transform0 = transforms.Compose([\n",
    "                                #transforms.RandomRotation(20),         #图像旋转的角度\n",
    "                                #transforms.RandomHorizontalFlip(),    #水平方向翻转\n",
    "                                transforms.ToTensor(),\n",
    "                                normalize()\n",
    "                                ])\n",
    "dataset = ImageFolder(\"D:\\\\newfolder43_1\",transform=transform0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "num_epoches = 300\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset0 = var_dataset(\"D:\\\\newfolder43_1\")\n",
    "dataset0[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset0,batch_size=batch_size,shuffle=True)\n",
    "#dataiter = iter(dataloader)\n",
    "#imgs,labels = next(dataiter)\n",
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=224\n",
    "n_hidden_1=64\n",
    "n_hidden_2=32\n",
    "n_hidden_3=16\n",
    "output_dim=2\n",
    "model = FC_Net(input_dim,n_hidden_1,n_hidden_2,n_hidden_3,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if t.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.cuda() \n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate,weight_decay=weight_decay) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start time  <===>   time.struct_time(tm_year=2018, tm_mon=6, tm_mday=13, tm_hour=20, tm_min=37, tm_sec=29, tm_wday=2, tm_yday=164, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "print(\"training start time  <===>  \",time.localtime())\n",
    "sum_loss = t.Tensor([0])\n",
    "for epoch in range(0,num_epoches):\n",
    "    for i,data in enumerate(dataloader,0):\n",
    "        data_batch, label = data        \n",
    "        data_batch, label = Variable(data_batch.float()).cuda(),Variable(label).cuda()\n",
    "        output = model(data_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output,label)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss = t.cat((sum_loss,loss.cpu().data),0)\n",
    "        x = i+epoch*len(dataloader)\n",
    "        if x%50 == 49:\n",
    "            loss_aver = sum_loss.mean()\n",
    "            sum_loss = t.Tensor([0])\n",
    "            vis.line(X=t.Tensor([x]), Y=t.Tensor([loss_aver]), win='blur2',opts={'title': 'loss-batch1', 'xlabel':'batch_num','ylabel':'loss_aver'},update='append' if x>49 else None)\n",
    "            #vis.updateTrace(X=t.Tensor([x]),Y=t.Tensor([loss_aver]),win='face_angle', name='7')\n",
    "t.save(model.state_dict(),\"C:\\\\Users\\\\SiChen\\\\face_sys\\\\grad_var_full_layers\\\\model_save\\\\fc_network_300_64_32_NoSoftmax_224_guiyihua_0.5Normalize_lr1e-4.pth\") \n",
    "print(\"training start time  <===>  \",time.localtime())                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#以下是测试部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2854\n",
      "[torch.IntTensor of size 1]\n",
      "\n",
      "3172\n",
      "0.8997477931904161\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_right_num = 0\n",
    "test_right_num = t.Tensor([test_right_num]).int()\n",
    "test_right_num = Variable(test_right_num)\n",
    "\n",
    "test_dataset = var_dataset(\"D:\\\\newfolder43_2\")\n",
    "for img0, label0 in test_dataset:\n",
    "    img0 = Variable(img0).view(1,224).cuda()\n",
    "    label0 = Variable(t.Tensor([label0]).long()).cuda()\n",
    "    output = model(img0)\n",
    "    \n",
    "    _,pred = t.max(output.cpu(),1)\n",
    "    num_correct = (pred==label0.cpu()).sum()\n",
    "    num_correct = num_correct.int()\n",
    "    test_right_num = test_right_num + num_correct\n",
    "    \n",
    "acc = (float(test_right_num))/len(test_dataset)\n",
    "print(test_right_num)\n",
    "print(len(test_dataset))\n",
    "print(acc)    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
