{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.autograd import Variable as V\n",
    "\n",
    "\n",
    "\n",
    "class Linear(nn.Module): \n",
    "    def __init__(self,in_features,out_features):\n",
    "        super().__init__()   #与python2.7不同，此处super里面不用参数\n",
    "        self.w = nn.Parameter(t.randn(in_features,out_features))\n",
    "        self.b = nn.Parameter(t.randn(out_features))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x.mm(self.w)\n",
    "        return x + self.b.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.9238  3.0967  0.4950\n",
       "-0.5025 -0.0759 -0.9008\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.manual_seed(1000)\n",
    "layer = Linear(4,3)\n",
    "input = V(t.randn(2,4))\n",
    "output = layer(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w Parameter containing:\n",
      "-1.1720 -0.3929  0.5265\n",
      " 1.1065  0.9273 -1.7421\n",
      "-0.7699  0.7864 -1.9963\n",
      " 0.5836  1.0392  0.8023\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n",
      "b Parameter containing:\n",
      " 0.5269\n",
      " 0.5730\n",
      " 0.1390\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name,parameter in layer.named_parameters():\n",
    "    print(name,parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self,in_features,hidden_features,out_features):\n",
    "        super().__init__()\n",
    "        self.layer1 = Linear(in_features,hidden_features)\n",
    "        self.layer2 = Linear(hidden_features,out_features)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        #t.save(x,'x_save.pth')\n",
    "        x = t.sigmoid(x)\n",
    "        return self.layer2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0210  0.0168  0.4278 -0.0272\n",
      "-0.0026 -0.0101 -0.0290  0.0068\n",
      "-0.0060 -0.0077 -0.1136  0.0090\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.manual_seed(1000)\n",
    "perceptron = Perceptron(3,4,1)\n",
    "#for name,parameter in perceptron.named_parameters():\n",
    "#    print(name,parameter.size())\n",
    "    \n",
    "input1 = V(t.randn(2,3),requires_grad = True)\n",
    "output1 = perceptron(input1)\n",
    "output1.backward(output1)\n",
    "#print(output1)\n",
    "print(perceptron.layer1.w.grad)\n",
    "#print(perceptron.layer1.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.1646\n",
       " 0.0305\n",
       "-0.5842\n",
       " 2.0983\n",
       "[torch.FloatTensor of size 4x1]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perceptron.state_dict().keys()\n",
    "#perceptron.state_dict().items()\n",
    "tt = perceptron.state_dict()\n",
    "tt['layer2.w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.7675 -1.4832 -3.2355 -0.8591\n",
       "-0.3966  0.0558  2.3588 -1.4629\n",
       "[torch.FloatTensor of size 2x4]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#t.save(perceptron.state_dict(),'pp.pth')\n",
    "#perceptron.load_state_dict(t.load('pp.pth'))\n",
    "y = t.load('x_save.pth',map_location=lambda storage,loc:storage)\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
